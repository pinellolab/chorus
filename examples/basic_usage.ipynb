{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chorus Basic Usage\n",
    "\n",
    "This notebook provides a quick introduction to using Chorus for genomic sequence predictions.\n",
    "\n",
    "**Note**: This notebook has been updated to reflect the new features including environment isolation and reference genome support."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "First, make sure Chorus is installed:\n",
    "\n",
    "```bash\n",
    "pip install -e /path/to/chorus\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Chorus and Create an Oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chorus\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Create an oracle instance\n",
    "# We'll use Enformer as it's currently the only fully implemented oracle\n",
    "# use_environment=True runs it in an isolated conda environment\n",
    "oracle = chorus.create_oracle('enformer', use_environment=True)\n",
    "\n",
    "# Check oracle status\n",
    "print(f\"Oracle type: {oracle.__class__.__name__}\")\n",
    "print(f\"Using environment: {oracle.use_environment}\")\n",
    "print(f\"Model loaded: {oracle.loaded}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Pre-trained Model\n",
    "\n",
    "Note: This will download the Enformer model from TensorFlow Hub (several GB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained Enformer model\n",
    "print(\"Loading model (this may take a moment)...\")\n",
    "# oracle.load_pretrained_model()  # Uncomment to actually load\n",
    "print(\"Model would be loaded here - uncomment the line above to load\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Explore Available Assays and Cell Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available assay types\n",
    "assay_types = oracle.list_assay_types()\n",
    "print(f\"Available assay types ({len(assay_types)}):\")\n",
    "print(assay_types[:5], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available cell types\n",
    "cell_types = oracle.list_cell_types()\n",
    "print(f\"Available cell types ({len(cell_types)}):\")\n",
    "print(cell_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Working with Tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample track\n",
    "track_data = pd.DataFrame({\n",
    "    'chrom': ['chr1'] * 10,\n",
    "    'start': range(0, 1000, 100),\n",
    "    'end': range(100, 1100, 100),\n",
    "    'value': np.random.rand(10) * 10\n",
    "})\n",
    "\n",
    "track = chorus.Track(\n",
    "    name=\"sample_track\",\n",
    "    assay_type=\"DNase\",\n",
    "    cell_type=\"K562\",\n",
    "    data=track_data\n",
    ")\n",
    "\n",
    "print(f\"Created track: {track.name}\")\n",
    "print(f\"Data shape: {track.data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save track to BedGraph file\n",
    "track.to_bedgraph(\"sample_track.bedgraph\")\n",
    "print(\"Track saved to sample_track.bedgraph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the track\n",
    "normalized_track = track.normalize(method='zscore')\n",
    "print(f\"Original values: {track.data['value'].values[:5]}\")\n",
    "print(f\"Normalized values: {normalized_track.data['value'].values[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Sequence Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example DNA sequence\n",
    "seq = \"ATCGATCGATCGATCGATCGATCGATCGATCG\"\n",
    "\n",
    "# Validate sequence\n",
    "is_valid = chorus.validate_sequence(seq)\n",
    "print(f\"Sequence valid: {is_valid}\")\n",
    "\n",
    "# Get GC content\n",
    "gc_content = chorus.get_gc_content(seq)\n",
    "print(f\"GC content: {gc_content:.2%}\")\n",
    "\n",
    "# Reverse complement\n",
    "rev_comp = chorus.reverse_complement(seq)\n",
    "print(f\"Original:  {seq}\")\n",
    "print(f\"Rev comp:  {rev_comp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a variant\n",
    "ref_seq = \"ATCGATCGATCGATCGATCGATCGATCGATCG\"\n",
    "position = 10\n",
    "ref_allele = \"C\"\n",
    "alt_allele = \"T\"\n",
    "\n",
    "variant_seq = chorus.apply_variant(ref_seq, position, ref_allele, alt_allele)\n",
    "print(f\"Reference: {ref_seq}\")\n",
    "print(f\"Variant:   {variant_seq}\")\n",
    "print(f\"Changed position {position}: {ref_allele} -> {alt_allele}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Making Predictions (Requires Loaded Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW: Simplified prediction API with reference genome support\n",
    "# Example of the new prediction interface (requires model to be loaded)\n",
    "\n",
    "# Method 1: Predict from sequence\n",
    "sequence = \"ACGT\" * 1000  # 4kb sequence\n",
    "# predictions = oracle.predict(sequence, ['DNase:K562', 'ATAC-seq:K562'])\n",
    "\n",
    "# Method 2: Predict from genomic coordinates (requires reference genome)\n",
    "# First create oracle with reference genome\n",
    "# oracle_with_ref = chorus.create_oracle(\n",
    "#     'enformer', \n",
    "#     use_environment=True,\n",
    "#     reference_fasta='/path/to/hg38.fa'\n",
    "# )\n",
    "# oracle_with_ref.load_pretrained_model()\n",
    "#\n",
    "# # Then predict using coordinates\n",
    "# predictions = oracle_with_ref.predict(\n",
    "#     ('chrX', 48780505, 48785229),  # (chrom, start, end)\n",
    "#     ['ENCFF413AHU']  # Can use ENCODE identifiers\n",
    "# )\n",
    "\n",
    "print(\"The new API supports both sequence and coordinate-based predictions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample tracks for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate sample data\n",
    "n_positions = 100\n",
    "positions = np.arange(n_positions) * 128  # 128bp bins\n",
    "\n",
    "# Create multiple tracks with different patterns\n",
    "tracks_to_viz = []\n",
    "for i, (name, pattern) in enumerate([\n",
    "    (\"DNase\", lambda x: np.sin(x/10) + np.random.randn(len(x))*0.1),\n",
    "    (\"H3K27ac\", lambda x: np.cos(x/15) + np.random.randn(len(x))*0.1),\n",
    "    (\"RNA-seq\", lambda x: np.exp(-x/50) + np.random.randn(len(x))*0.05)\n",
    "]):\n",
    "    values = pattern(positions/1000)\n",
    "    values = (values - values.min()) / (values.max() - values.min())  # Normalize to [0,1]\n",
    "    \n",
    "    track_data = pd.DataFrame({\n",
    "        'chrom': ['chr1'] * n_positions,\n",
    "        'start': positions,\n",
    "        'end': positions + 128,\n",
    "        'value': values\n",
    "    })\n",
    "    \n",
    "    # Save to file\n",
    "    filename = f\"example_{name}.bedgraph\"\n",
    "    track = chorus.Track(\n",
    "        name=name,\n",
    "        assay_type=name,\n",
    "        cell_type=\"K562\",\n",
    "        data=track_data\n",
    "    )\n",
    "    track.to_bedgraph(filename)\n",
    "    tracks_to_viz.append(filename)\n",
    "\n",
    "# Visualize tracks\n",
    "chorus.visualize_tracks(\n",
    "    tracks_filenames=tracks_to_viz,\n",
    "    track_names=[\"DNase\", \"H3K27ac\", \"RNA-seq\"],\n",
    "    colors=['blue', 'green', 'red'],\n",
    "    figure_size=(10, 6),\n",
    "    output_file=\"example_tracks.png\"\n",
    ")\n",
    "\n",
    "print(\"Visualization saved to example_tracks.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Next Steps\n",
    "\n",
    "For more advanced usage:\n",
    "- See `enformer_updated_example.ipynb` for the latest Enformer features\n",
    "- See `enformer_example.ipynb` for detailed Enformer predictions\n",
    "- See `variant_analysis.ipynb` for variant effect prediction\n",
    "- Check the documentation for environment setup and management\n",
    "\n",
    "### Key New Features:\n",
    "1. **Environment Isolation**: Each oracle runs in its own conda environment\n",
    "2. **Reference Genome Support**: Automatic sequence extraction with proper padding\n",
    "3. **ENCODE Identifiers**: Use specific experiment IDs like 'ENCFF413AHU'\n",
    "4. **Simplified API**: Single `predict()` method for all use cases"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}